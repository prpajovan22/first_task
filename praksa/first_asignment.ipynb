{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import pandas as pd;\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"bbc-news-data.csv\"\n",
    "data = pd.read_csv(file,sep=\"\\t\") \n",
    "                                                                \n",
    "data.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "data = data.dropna().drop_duplicates()\n",
    "\n",
    "data.replace(\",\",\"\",regex=True,inplace=True)\n",
    "data.replace(r'\\s+', ' ', regex=True, inplace=True)\n",
    "data['title'] = data['title'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "data['content'] = data['content'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming  data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop([\"category\"],axis=1)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['brand']= data[\"content\"].str.split().str.get(3)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Model'] = data[\"title\"].str.split().str.get(1) + data[\"title\"].str.split().str.get(2)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Model'] = data[\"title\"].str.split().str.get(1) + data[\"title\"].str.split().str.get(2)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>new content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at United States, media gia...</td>\n",
       "      <td>quarterly profit at us medium giant timewarner...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category filename                              title  \\\n",
       "0  business  001.txt  Ad sales boost Time Warner profit   \n",
       "\n",
       "                                             content  \\\n",
       "0   Quarterly profits at United States, media gia...   \n",
       "\n",
       "                                         new content  \n",
       "0  quarterly profit at us medium giant timewarner...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.at[0, 'content'] = data.at[0, 'content'].replace('US', 'United States,')\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "for words in data:\n",
    "    print(words,\"|\",stemmer.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.tokenize.WhitespaceTokenizer().tokenize(data[\"content\"][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.tokenize.WordPunctTokenizer().tokenize(data[\"content\"][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.tokenize.TreebankWordTokenizer().tokenize(data[\"content\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words  = nltk.tokenize.WhitespaceTokenizer().tokenize(data[\"content\"][2])\n",
    "df = pd.DataFrame()\n",
    "df['OriginalWords'] = pd.Series(words)\n",
    "\n",
    "porterStemmedWords = [nltk.stem.PorterStemmer().stem(word) for word in words]\n",
    "df['PorterStemmedWords'] = pd.Series(porterStemmedWords)\n",
    "\n",
    "snowballStemmedWords = [nltk.stem.SnowballStemmer(\"english\").stem(word) for word in words]\n",
    "df['SnowballStemmedWords'] = pd.Series(snowballStemmedWords)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = nltk.tokenize.WhitespaceTokenizer().tokenize(data[\"content\"][0])\n",
    "df = pd.DataFrame()\n",
    "df[\"Old\"] = pd.Series(words)\n",
    "\n",
    "wordNetLemmatizedWords = [nltk.stem.WordNetLemmatizer().lemmatize(word) for word in words]\n",
    "df[\"New\"] = pd.Series(wordNetLemmatizedWords)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_lemmatize(text):\n",
    "    data.astype(str).apply(lambda x: x.str.encode('ascii', 'ignore').str.decode('ascii'))\n",
    "    words = nltk.tokenize.WhitespaceTokenizer().tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words).lower()\n",
    "\n",
    "data['new content'] = data['content'].apply(tokenize_and_lemmatize)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.get_dummies(data,columns=['filename'])\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemitizacija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soret = data.sort_values(by=[\"Model\"])\n",
    "display(soret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include=\"all\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_filename=data.filter(['title','content'])\n",
    "display(no_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = data.copy()\n",
    "new['content'] = new['content'].replace(to_replace = ('US','UK'),value =('United States','United Kingdom'),regex=True)\n",
    "\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data.isnull().sum()/(len(data)))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = data.copy()\n",
    "copy[\"filename\"] = copy[\"filename\"].replace(to_replace = \".txt\",value = \"\", regex= True)\n",
    "\n",
    "copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2= data[(data[\"category\"].str.endswith(\"sport\"))]\n",
    "\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1= data[(data[\"title\"].str.startswith(\"Dollar\"))]\n",
    "\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficki prikazi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category'].hist()\n",
    "\n",
    "for i in range(len(data['category'].value_counts())):\n",
    "    plt.text(i, data['category'].value_counts().iloc[i], str(data['category'].value_counts().iloc[i]), ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_values = data.pivot_table(columns=['category'], aggfunc='size')\n",
    "category_names = data['category']\n",
    "categories = category_names.unique()\n",
    "categories.sort()\n",
    "\n",
    "total = category_values.sum()\n",
    "category_percentages = category_values / total * 100\n",
    "\n",
    "plt.pie(category_percentages, labels=categories, autopct='%1.1f%%')\n",
    "\n",
    "my_circle = plt.Circle((0, 0), 0.7, color='white')\n",
    "plt.gca().add_artist(my_circle)\n",
    "\n",
    "plt.axis('equal')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(x=[1,2,3], y=[1, 2,4]) \n",
    " \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.iris()\n",
    "\n",
    "fig = px.bar(df,x = \"sepal_width\",y=\"sepal_length\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.iris()\n",
    "fig = px.scatter(df,x = \"species\", y = \"petal_width\",size=\"petal_length\",color=\"species\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.tips()\n",
    "fig = px.pie(df,values = \"total_bill\",names=\"day\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols= data.select_dtypes(include=[\"object\"]).columns\n",
    "num_cols = data.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(3,2, figsize = (9,9))\n",
    "fig.suptitle('Bar plot for all categorical variables in the dataset')\n",
    "sns.countplot(ax = axes[0, 0], x = 'title', data = data, color = 'red', \n",
    "              order = data['title'].value_counts().index);\n",
    "sns.countplot(ax = axes[0, 1], x = 'category', data = data, color = 'green', \n",
    "              order = data['category'].value_counts().index);\n",
    "sns.countplot(ax = axes[1, 0], x = 'filename', data = data, color = 'yellow', \n",
    "              order = data['filename'].value_counts().index);\n",
    "axes[1][1].tick_params(labelrotation=45);\n",
    "axes[2][0].tick_params(labelrotation=90);\n",
    "axes[2][1].tick_params(labelrotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = px.data.iris() \n",
    " \n",
    "fig = px.scatter_3d(df, x = 'sepal_width', \n",
    "                    y = 'sepal_length', \n",
    "                    z = 'petal_width', \n",
    "                    color = 'species') \n",
    " \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1, 2],\n",
    "    y=[1, 1, 1],\n",
    "    mode=\"lines+markers+text\",\n",
    "    name=\"Lines, Markers and Text\",\n",
    "    text=[\"Text A\", \"Text B\", \"Text C\"],\n",
    "    textposition=\"top center\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1, 2],\n",
    "    y=[2, 2, 2],\n",
    "    mode=\"markers+text\",\n",
    "    name=\"Markers and Text\",\n",
    "    text=[\"Text D\", \"Text E\", \"Text F\"],\n",
    "    textposition=\"bottom center\"\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1, 2],\n",
    "    y=[3, 3, 3],\n",
    "    mode=\"lines+text\",\n",
    "    name=\"Lines and Text\",\n",
    "    text=[\"Text G\", \"Text H\", \"Text I\"],\n",
    "    textposition=\"bottom center\"\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = px.data.gapminder(year=2007)\n",
    "fig = px.bar(data, x='category', \n",
    "             title=\"Default behavior: some text is tiny\")\n",
    "fig.update_traces(textposition='inside')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "praksa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
